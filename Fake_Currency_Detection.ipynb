{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahkswarun/Fake-Currency-Detection-System-Using-Deep-Learning-and-MobileNetV3/blob/main/Fake_Currency_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "T7_-KRfhr1R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TzTCHm_Wqsjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BdZLHgT6vnA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import shuffle, class_weight\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from collections import Counter\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ULPYIH_68RL"
      },
      "outputs": [],
      "source": [
        "# Define labels\n",
        "\n",
        "class_names = ['fifty fake', 'fifty original', 'five hundred fake', 'five hundred original',\n",
        "               'hundred fake', 'hundred original', 'ten fake', 'ten original',\n",
        "               'twenty fake', 'twenty original', 'two hundred fake', 'two hundred original',\n",
        "               'two thousand fake', 'two thousand original']\n",
        "\n",
        "class_names_label = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "nb_classes = len(class_names)\n",
        "IMAGE_SIZE = (448,224) #(300,150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ebZ7JL27V-I"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess dataset\n",
        "def load_data():\n",
        "    datasets = [r\"/content/drive/MyDrive/PJT 2/fake currency using CNN/dataset\"]\n",
        "    output = []\n",
        "\n",
        "    for dataset in datasets:\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        print(f\"Loading {dataset}\")\n",
        "\n",
        "        for folder in os.listdir(dataset):\n",
        "            folder_path = os.path.join(dataset, folder)\n",
        "            if not os.path.isdir(folder_path):\n",
        "                continue\n",
        "\n",
        "            if folder not in class_names_label:\n",
        "                print(f\"Warning: '{folder}' not found in class_names_label. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            label = class_names_label[folder]\n",
        "\n",
        "            for file in tqdm(os.listdir(folder_path)):\n",
        "                img_path = os.path.join(folder_path, file)\n",
        "                try:\n",
        "                    image = cv2.imread(img_path)\n",
        "                    if image is None:\n",
        "                        print(f\"Warning: Failed to load image {img_path}. Skipping.\")\n",
        "                        continue\n",
        "\n",
        "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                    image = cv2.resize(image, IMAGE_SIZE)\n",
        "                    images.append(image)\n",
        "                    labels.append(label)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image {img_path}: {e}\")\n",
        "                    continue\n",
        "\n",
        "        images = np.array(images)\n",
        "        labels = np.array(labels)\n",
        "        output.append((images, labels))\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACQk-yA-7YBe"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54kpu7lS8xk6"
      },
      "outputs": [],
      "source": [
        "# Shuffle training data\n",
        "train_images, train_labels = shuffle(train_images, train_labels, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8hq-o79DfhD"
      },
      "outputs": [],
      "source": [
        "\n",
        "_, train_counts = np.unique(train_labels, return_counts=True)\n",
        "pd.DataFrame({'train': train_counts},index=class_names).plot.barh()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQbgZDamDyu7"
      },
      "outputs": [],
      "source": [
        "# PyTorch Dataset Class\n",
        "class CurrencyDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYPyRbF48zt1"
      },
      "outputs": [],
      "source": [
        "# Split into training (80%) and validation (20%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjFrJKUT6rQA"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation and Normalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomResizedCrop((224, 448)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224,448)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "# Create Datasets and Dataloaders\n",
        "train_dataset = CurrencyDataset(X_train, y_train, transform=train_transform)\n",
        "val_dataset = CurrencyDataset(X_val, y_val, transform=test_transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "# Load Pretrained MobileNetV3 Model\n",
        "model = models.mobilenet_v3_large(pretrained=True)\n",
        "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 14)  # 14 classes as per our dataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adamax(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Function\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25):\n",
        "    best_val_acc = 0.0\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "        epoch_train_loss = running_loss / total_train\n",
        "        epoch_train_acc = running_corrects.double() / total_train\n",
        "        history['train_loss'].append(epoch_train_loss)\n",
        "        history['train_acc'].append(epoch_train_acc.item())\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                val_corrects += torch.sum(preds == labels.data)\n",
        "                total_val += labels.size(0)\n",
        "\n",
        "        epoch_val_loss = val_loss / total_val\n",
        "        epoch_val_acc = val_corrects.double() / total_val\n",
        "        history['val_loss'].append(epoch_val_loss)\n",
        "        history['val_acc'].append(epoch_val_acc.item())\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
        "        print(f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}')\n",
        "        print(f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}')\n",
        "\n",
        "        # Save best model\n",
        "        if epoch_val_acc > best_val_acc:\n",
        "            best_val_acc = epoch_val_acc\n",
        "            model_save_path = '/content/drive/MyDrive/PJT 2/fake currency using CNN/best_model.pth'\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "            print('✅ Best model saved!')\n",
        "\n",
        "    print('Training Complete.')\n",
        "    return history\n",
        "\n",
        "# Train the model\n",
        "history = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vciIQDHr6YW_"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/PJT 2/fake currency using CNN/best_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CYlFn63EoX_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Plot Training Results\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='Training Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss over Epochs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-AZFSByEp0v",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['train_acc'], label='Training Accuracy')\n",
        "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U44BZVwhISKG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# Evaluation Function for Metrics Calculation\n",
        "def evaluate_model_metrics(model, data_loader, labels):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, label_batch in data_loader:\n",
        "            images = images.to(device)\n",
        "            label_batch = label_batch.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "            if label_batch.dim() == 0:  # Handle 0-dim tensor case\n",
        "                all_labels.append(label_batch.item())\n",
        "            else:\n",
        "                all_labels.extend(label_batch.cpu().numpy())\n",
        "\n",
        "    # Calculate Metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(all_labels, all_preds, labels=range(len(labels)), target_names=labels))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds, labels=range(len(labels)))\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('True Class')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate on Validation Set\n",
        "print(\"Validation Set Evaluation:\")\n",
        "evaluate_model_metrics(model, val_loader, class_names)\n",
        "\n",
        "# Evaluate on Test Set\n",
        "# print(\"Test Set Evaluation:\")\n",
        "# evaluate_model_metrics(model, test_loader, class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIm0pYrkJf_1"
      },
      "outputs": [],
      "source": [
        "# Save the PyTorch model weights\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/PJT 2/fake currency using CNN/model_mobilenetv3_weights.pth\")\n",
        "print(\"Model weights saved successfully.\")\n",
        "\n",
        "# Save the entire PyTorch model\n",
        "torch.save(model, \"/content/drive/MyDrive/PJT 2/fake currency using CNN/full_model_mobilenetv3.pth\")\n",
        "print(\"Full model saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c15GiZGAv_mu"
      },
      "source": [
        "**FLASK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iN-Gr3THmaZV"
      },
      "outputs": [],
      "source": [
        "#necessary packages\n",
        "!pip install flask pyngrok torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgtT-4BkJhhL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from flask import Flask, render_template, request, send_from_directory\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pyngrok import ngrok\n",
        "\n",
        "\n",
        "app = Flask(__name__, template_folder='/content/drive/MyDrive/PJT 2/fake currency using CNN/templates')\n",
        "\n",
        "# Define folders\n",
        "UPLOAD_FOLDER = '/content/drive/MyDrive/PJT 2/fake currency using CNN/uploads'\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "\n",
        "# Model path\n",
        "model_path = '/content/drive/MyDrive/PJT 2/fake currency using CNN/best_model.pth'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the trained PyTorch model\n",
        "model = models.mobilenet_v3_large(pretrained=True)\n",
        "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 14)  # Adjusting the final layer for 14 classes\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print('✅ Model loaded successfully.')\n",
        "\n",
        "# Image Preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,448)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Label Names (Match this with your training data classes)\n",
        "label_names = [\n",
        "    'fifty fake', 'fifty original', 'five hundred fake', 'five hundred original',\n",
        "    'hundred fake', 'hundred original', 'ten fake', 'ten original',\n",
        "    'twenty fake', 'twenty original', 'two hundred fake', 'two hundred original',\n",
        "    'two thousand fake', 'two thousand original'\n",
        "]\n",
        "\n",
        "# Predict & classify image\n",
        "def classify(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        prob, predicted_label_index = torch.max(probabilities, 1)\n",
        "        label = label_names[predicted_label_index.item()]\n",
        "        classified_prob = round(prob.item() * 100, 2)\n",
        "\n",
        "    return label, classified_prob\n",
        "\n",
        "# Home page\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('home2.html')\n",
        "\n",
        "# Classify page\n",
        "@app.route('/classify', methods=['POST', 'GET'])\n",
        "def upload_file():\n",
        "    if request.method == 'POST':\n",
        "        if 'image' not in request.files:\n",
        "            return 'No file uploaded', 400\n",
        "\n",
        "        file = request.files['image']\n",
        "        if file.filename == '':\n",
        "            return 'No selected file', 400\n",
        "\n",
        "        upload_image_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
        "        file.save(upload_image_path)\n",
        "\n",
        "        label, prob = classify(upload_image_path)\n",
        "\n",
        "        return render_template('classify2.html', label=label, prob=prob, image_file_name=file.filename)\n",
        "    return 'Invalid Request', 400\n",
        "\n",
        "# Serve uploaded images\n",
        "@app.route('/uploads/<filename>')\n",
        "def send_file(filename):\n",
        "    return send_from_directory(UPLOAD_FOLDER, filename)\n",
        "\n",
        "# Run the app using pyngrok\n",
        "if __name__ == '__main__':\n",
        "    ngrok.set_auth_token('2ucG6F5qIjzOpAezBg7MV5lkknN_4DfWb1VXb2ygeoz6zMNyo')  # Add ngrok token here\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f'Your app is running here: {public_url}')\n",
        "    app.run(port=5000)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}